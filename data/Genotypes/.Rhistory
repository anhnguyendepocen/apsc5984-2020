new.y = as.matrix(new.ph[,5, drop = F]) %*% t(rep(1, 2))
colnames(new.y) = paste0("Y", 1:2)
##merge the fold x n matrix and the phenotypic dada
new.ph1 = cbind(new.ph, new.y)[,ncol(new.ph):(ncol(new.ph)+2)]
#2. Mask the observations in each fold
##This function will assign NA to all obervations from the accessions belonging to a given fold
missingInFold = function(r){
fold = r["Fold"]
index = fold + 1
r[index] = NA
return(r)
}
##Assign the NA's
new.ph2 = t(apply(new.ph1, 1, missingInFold))
##Merge this with the orignial dataframe
if(i == 1){
final=cbind(new.ph[,1:(ncol(new.ph)-1)], new.ph2[,2:3])
}else{
final=cbind(final, new.ph2[,2:3])
}
}
#3. Order the dataframe and write it to a file
final=final[order(final$NSFTV.ID, final$Exp, final$Rep, final$DayOfImaging) ,]
colnames(final)[6:ncol(final)]=paste0("Y", 1:(N*2))
write.csv(final, paste0("~/Desktop/Aus_Drought_RRBLUP/Final/Ratio/RR/CV/", Trait[Tr], "_CV.csv"), row.names=F)
}
final=read.csv("~/Desktop/ASREML_SA/RR_PSA.Cont/ScenarioD_CV/TP.5/final.CV_ScenD_5.csv")
setwd("~/Desktop/ASREML_SA/RR_PSA.Cont/ScenarioD_CV/TP.5/")
Files=c("PSA.sln", paste0("Y", 1:20, ".sln"))
i=
1
sln=read.delim(Files[i], sep="", header=T)
g.hat.y=t(cbind(sln[grep("1.NSFTV", sln$Level) ,][,3],
sln[grep("2.NSFTV", sln$Level) ,][,3],
sln[grep("3.NSFTV", sln$Level) ,][,3]))
colnames(g.hat.y)=sub("1.", "", sln[grep("1.NSFTV", sln$Level) ,][,2])
Phi = stdtime(1:20, 2) %*% t(legendre(2, gengler = F))
ghat.t.y = t(apply(g.hat.y, 2, function (x) Phi %*% x))
colnames(ghat.t.y)=1:20
gBLUP.all=melt(ghat.t.y)
colnames(gBLUP.all)=c("NSFTV.ID", "DayOfImaging", "gBLUP")
sln=read.delim(Files[i], sep="", header=T)
g.hat.y=t(cbind(sln[grep("1.NSFTV", sln$Level) ,][,3],
sln[grep("2.NSFTV", sln$Level) ,][,3],
sln[grep("3.NSFTV", sln$Level) ,][,3]))
colnames(g.hat.y)=sub("1.", "", sln[grep("1.NSFTV", sln$Level) ,][,2])
Phi = stdtime(1:20, 2) %*% t(legendre(2, gengler = F))
ghat.t.y = t(apply(g.hat.y, 2, function (x) Phi %*% x))
colnames(ghat.t.y)=1:20
gBLUP=melt(ghat.t.y)
colnames(gBLUP)=c("NSFTV.ID", "DayOfImaging", "gBLUP")
final=read.csv("~/Desktop/ASREML_SA/RR_PSA.Cont/ScenarioD_CV/TP.5/final.CV_ScenD_5.csv")
setwd("~/Desktop/ASREML_SA/RR_PSA.Cont/ScenarioD_CV/TP.5/")
Files=c("PSA.sln", paste0("Y", 1:20, ".sln"))
for (i in 1:length(Files)){
if(Files[i] == "PSA.sln"){
#Requires the gBLUPs for PSA from the RR with ALL 20 timepoints
sln=read.delim(Files[i], sep="", header=T)
g.hat.y=t(cbind(sln[grep("1.NSFTV", sln$Level) ,][,3],
sln[grep("2.NSFTV", sln$Level) ,][,3],
sln[grep("3.NSFTV", sln$Level) ,][,3]))
colnames(g.hat.y)=sub("1.", "", sln[grep("1.NSFTV", sln$Level) ,][,2])
Phi = stdtime(1:20, 2) %*% t(legendre(2, gengler = F))
ghat.t.y = t(apply(g.hat.y, 2, function (x) Phi %*% x))
colnames(ghat.t.y)=1:20
gBLUP.all=melt(ghat.t.y)
colnames(gBLUP.all)=c("NSFTV.ID", "DayOfImaging", "gBLUP")
}else{
sln=read.delim(Files[i], sep="", header=T)
g.hat.y=t(cbind(sln[grep("1.NSFTV", sln$Level) ,][,3],
sln[grep("2.NSFTV", sln$Level) ,][,3],
sln[grep("3.NSFTV", sln$Level) ,][,3]))
colnames(g.hat.y)=sub("1.", "", sln[grep("1.NSFTV", sln$Level) ,][,2])
Phi = stdtime(1:20, 2) %*% t(legendre(2, gengler = F))
ghat.t.y = t(apply(g.hat.y, 2, function (x) Phi %*% x))
colnames(ghat.t.y)=1:20
gBLUP=melt(ghat.t.y)
colnames(gBLUP)=c("NSFTV.ID", "DayOfImaging", "gBLUP")
if(i == 2 ){
final.blups=cbind(gBLUP.all, gBLUP[,3])
}else{
final.blups=cbind(final.blups, gBLUP[,3])
}
}
}
colnames(final.blups)[3:ncol(final.blups)]=sub(".sln", "", Files)
Cor.res.TP5=matrix(0, ncol=20, nrow=20)
for(j in 2:length(Files)){
tmp=final[c("NSFTV.ID", colnames(final.blups)[j+2])]
colnames(tmp)[2]="Y"
tmp=ddply(tmp, .(NSFTV.ID), summarise, Cnt=sum(is.na(Y)))
test.accTP.5=tmp[ tmp$Cnt == 30 ,]$NSFTV.ID
Cor.resTP.5[,j-1]=ldply(dlply(final.blups[final.blups$NSFTV.ID %in% test.accTP.5 ,][c(1,2,3,j+2)],
.(DayOfImaging), function(x) cor(x$PSA, x[,4], use="complete.obs") ) )[,2]
}
j=2
tmp=final[c("NSFTV.ID", colnames(final.blups)[j+2])]
colnames(tmp)[2]="Y"
tmp=ddply(tmp, .(NSFTV.ID), summarise, Cnt=sum(is.na(Y)))
test.accTP.5=tmp[ tmp$Cnt == 30 ,]$NSFTV.ID
summary(tmp)
Cor.res.TP.5=matrix(0, ncol=20, nrow=20)
for(j in 2:length(Files)){
tmp=final[c("NSFTV.ID", colnames(final.blups)[j+2])]
colnames(tmp)[2]="Y"
tmp=ddply(tmp, .(NSFTV.ID), summarise, Cnt=sum(is.na(Y)))
test.accTP.5=tmp[ tmp$Cnt == 30 ,]$NSFTV.ID
Cor.resTP.5[,j-1]=ldply(dlply(final.blups[final.blups$NSFTV.ID %in% test.accTP.5 ,][c(1,2,3,j+2)],
.(DayOfImaging), function(x) cor(x$PSA, x[,4], use="complete.obs") ) )[,2]
}
Cor.resTP.5.mean=apply(Cor.resTP.5, 1, mean)
Cor.resTP.5.sd=apply(Cor.resTP.5, 1, sd)
Cor.resTP.5=matrix(0, ncol=20, nrow=20)
for(j in 2:length(Files)){
tmp=final[c("NSFTV.ID", colnames(final.blups)[j+2])]
colnames(tmp)[2]="Y"
tmp=ddply(tmp, .(NSFTV.ID), summarise, Cnt=sum(is.na(Y)))
test.accTP.5=tmp[ tmp$Cnt == 30 ,]$NSFTV.ID
Cor.resTP.5[,j-1]=ldply(dlply(final.blups[final.blups$NSFTV.ID %in% test.accTP.5 ,][c(1,2,3,j+2)],
.(DayOfImaging), function(x) cor(x$PSA, x[,4], use="complete.obs") ) )[,2]
}
Cor.resTP.5.mean=apply(Cor.resTP.5, 1, mean)
Cor.resTP.5.sd=apply(Cor.resTP.5, 1, sd)
Cor.resTP.5.mean
final=read.csv("~/Desktop/ASREML_SA/RR_PSA.Cont/ScenarioD_CV/TP.7/final.CV_ScenD_5.csv")
setwd("~/Desktop/ASREML_SA/RR_PSA.Cont/ScenarioD_CV/TP.7/")
Files=c("PSA.sln", paste0("Y", 1:20, ".sln"))
for (i in 1:length(Files)){
if(Files[i] == "PSA.sln"){
#Requires the gBLUPs for PSA from the RR with ALL 20 timepoints
sln=read.delim("~/Desktop/ASREML_SA/RR_PSA.Cont/RR2_2_10_CV/PSA.sln", sep="", header=T)
g.hat.y=t(cbind(sln[grep("1.NSFTV", sln$Level) ,][,3],
sln[grep("2.NSFTV", sln$Level) ,][,3],
sln[grep("3.NSFTV", sln$Level) ,][,3]))
colnames(g.hat.y)=sub("1.", "", sln[grep("1.NSFTV", sln$Level) ,][,2])
Phi = stdtime(1:20, 2) %*% t(legendre(2, gengler = F))
ghat.t.y = t(apply(g.hat.y, 2, function (x) Phi %*% x))
colnames(ghat.t.y)=1:20
gBLUP.all=melt(ghat.t.y)
colnames(gBLUP.all)=c("NSFTV.ID", "DayOfImaging", "gBLUP")
}else{
sln=read.delim(Files[i], sep="", header=T)
g.hat.y=t(cbind(sln[grep("1.NSFTV", sln$Level) ,][,3],
sln[grep("2.NSFTV", sln$Level) ,][,3],
sln[grep("3.NSFTV", sln$Level) ,][,3]))
colnames(g.hat.y)=sub("1.", "", sln[grep("1.NSFTV", sln$Level) ,][,2])
Phi = stdtime(1:20, 2) %*% t(legendre(2, gengler = F))
ghat.t.y = t(apply(g.hat.y, 2, function (x) Phi %*% x))
colnames(ghat.t.y)=1:20
gBLUP=melt(ghat.t.y)
colnames(gBLUP)=c("NSFTV.ID", "DayOfImaging", "gBLUP")
if(i == 2 ){
final.blups=cbind(gBLUP.all, gBLUP[,3])
}else{
final.blups=cbind(final.blups, gBLUP[,3])
}
}
}
colnames(final.blups)[3:ncol(final.blups)]=sub(".sln", "", Files)
Cor.resTP7=matrix(0, ncol=20, nrow=20)
j=2
tmp=final[c("NSFTV.ID", colnames(final.blups)[j+2])]
colnames(tmp)[2]="Y"
tmp=ddply(tmp, .(NSFTV.ID), summarise, Cnt=sum(is.na(Y)))
test.accTP.7=tmp[ tmp$Cnt == 30 ,]$NSFTV.ID
summary(tmp)
final=read.csv("~/Desktop/ASREML_SA/RR_PSA.Cont/ScenarioD_CV/TP.7/final.CV_ScenD_7.csv")
setwd("~/Desktop/ASREML_SA/RR_PSA.Cont/ScenarioD_CV/TP.7/")
Files=c("PSA.sln", paste0("Y", 1:20, ".sln"))
for (i in 1:length(Files)){
if(Files[i] == "PSA.sln"){
#Requires the gBLUPs for PSA from the RR with ALL 20 timepoints
sln=read.delim(Files[i], sep="", header=T)
g.hat.y=t(cbind(sln[grep("1.NSFTV", sln$Level) ,][,3],
sln[grep("2.NSFTV", sln$Level) ,][,3],
sln[grep("3.NSFTV", sln$Level) ,][,3]))
colnames(g.hat.y)=sub("1.", "", sln[grep("1.NSFTV", sln$Level) ,][,2])
Phi = stdtime(1:20, 2) %*% t(legendre(2, gengler = F))
ghat.t.y = t(apply(g.hat.y, 2, function (x) Phi %*% x))
colnames(ghat.t.y)=1:20
gBLUP.all=melt(ghat.t.y)
colnames(gBLUP.all)=c("NSFTV.ID", "DayOfImaging", "gBLUP")
}else{
sln=read.delim(Files[i], sep="", header=T)
g.hat.y=t(cbind(sln[grep("1.NSFTV", sln$Level) ,][,3],
sln[grep("2.NSFTV", sln$Level) ,][,3],
sln[grep("3.NSFTV", sln$Level) ,][,3]))
colnames(g.hat.y)=sub("1.", "", sln[grep("1.NSFTV", sln$Level) ,][,2])
Phi = stdtime(1:20, 2) %*% t(legendre(2, gengler = F))
ghat.t.y = t(apply(g.hat.y, 2, function (x) Phi %*% x))
colnames(ghat.t.y)=1:20
gBLUP=melt(ghat.t.y)
colnames(gBLUP)=c("NSFTV.ID", "DayOfImaging", "gBLUP")
if(i == 2 ){
final.blups=cbind(gBLUP.all, gBLUP[,3])
}else{
final.blups=cbind(final.blups, gBLUP[,3])
}
}
}
colnames(final.blups)[3:ncol(final.blups)]=sub(".sln", "", Files)
Cor.resTP7=matrix(0, ncol=20, nrow=20)
tmp=final[c("NSFTV.ID", colnames(final.blups)[j+2])]
colnames(tmp)[2]="Y"
tmp=ddply(tmp, .(NSFTV.ID), summarise, Cnt=sum(is.na(Y)))
summary(tmp)
for(j in 2:length(Files)){
tmp=final[c("NSFTV.ID", colnames(final.blups)[j+2])]
colnames(tmp)[2]="Y"
tmp=ddply(tmp, .(NSFTV.ID), summarise, Cnt=sum(is.na(Y)))
test.accTP.7=tmp[ tmp$Cnt == 42 ,]$NSFTV.ID
Cor.resTP.7[,j-1]=ldply(dlply(final.blups[final.blups$NSFTV.ID %in% test.accTP.7 ,][c(1,2,3,j+2)],
.(DayOfImaging), function(x) cor(x$PSA, x[,4], use="complete.obs") ) )[,2]
}
Cor.resTP.7.mean=apply(Cor.resTP.7, 1, mean)
Cor.resTP.7.sd=apply(Cor.resTP.7, 1, sd)
Cor.resTP.7=matrix(0, ncol=20, nrow=20)
for(j in 2:length(Files)){
tmp=final[c("NSFTV.ID", colnames(final.blups)[j+2])]
colnames(tmp)[2]="Y"
tmp=ddply(tmp, .(NSFTV.ID), summarise, Cnt=sum(is.na(Y)))
test.accTP.7=tmp[ tmp$Cnt == 42 ,]$NSFTV.ID
Cor.resTP.7[,j-1]=ldply(dlply(final.blups[final.blups$NSFTV.ID %in% test.accTP.7 ,][c(1,2,3,j+2)],
.(DayOfImaging), function(x) cor(x$PSA, x[,4], use="complete.obs") ) )[,2]
}
Cor.resTP.7.mean=apply(Cor.resTP.7, 1, mean)
Cor.resTP.7.sd=apply(Cor.resTP.7, 1, sd)
Cor.resTP.7.mean
Cor.resTP.5.mean
for (i in 1:length(Files)){
if(Files[i] == "PSA.sln"){
#Requires the gBLUPs for PSA from the RR with ALL 20 timepoints
sln=read.delim(Files[i], sep="", header=T)
g.hat.y=t(cbind(sln[grep("1.NSFTV", sln$Level) ,][,3],
sln[grep("2.NSFTV", sln$Level) ,][,3],
sln[grep("3.NSFTV", sln$Level) ,][,3]))
colnames(g.hat.y)=sub("1.", "", sln[grep("1.NSFTV", sln$Level) ,][,2])
Phi = stdtime(1:20, 2) %*% t(legendre(2, gengler = F))
ghat.t.y = t(apply(g.hat.y, 2, function (x) Phi %*% x))
colnames(ghat.t.y)=1:20
gBLUP.all=melt(ghat.t.y)
colnames(gBLUP.all)=c("NSFTV.ID", "DayOfImaging", "gBLUP")
}else{
sln=read.delim(Files[i], sep="", header=T)
g.hat.y=t(cbind(sln[grep("1.NSFTV", sln$Level) ,][,3],
sln[grep("2.NSFTV", sln$Level) ,][,3],
sln[grep("3.NSFTV", sln$Level) ,][,3]))
colnames(g.hat.y)=sub("1.", "", sln[grep("1.NSFTV", sln$Level) ,][,2])
Phi = stdtime(1:20, 2) %*% t(legendre(2, gengler = F))
ghat.t.y = t(apply(g.hat.y, 2, function (x) Phi %*% x))
colnames(ghat.t.y)=1:20
gBLUP=melt(ghat.t.y)
colnames(gBLUP)=c("NSFTV.ID", "DayOfImaging", "gBLUP")
if(i == 2 ){
final.blups=cbind(gBLUP.all, gBLUP[,3])
}else{
final.blups=cbind(final.blups, gBLUP[,3])
}
}
}
colnames(final.blups)[3:ncol(final.blups)]=sub(".sln", "", Files)
tmp=final[c("NSFTV.ID", colnames(final.blups)[j+2])]
colnames(tmp)[2]="Y"
tmp=ddply(tmp, .(NSFTV.ID), summarise, Cnt=sum(is.na(Y)))
summary(tmp)
final=read.csv("~/Desktop/ASREML_SA/RR_PSA.Cont/ScenarioD_CV/TP.10/final.CV_ScenD_10.csv")
setwd("~/Desktop/ASREML_SA/RR_PSA.Cont/ScenarioD_CV/TP.10/")
Files=c("PSA.sln", paste0("Y", 1:20, ".sln"))
for (i in 1:length(Files)){
if(Files[i] == "PSA.sln"){
#Requires the gBLUPs for PSA from the RR with ALL 20 timepoints
sln=read.delim(Files[i], sep="", header=T)
g.hat.y=t(cbind(sln[grep("1.NSFTV", sln$Level) ,][,3],
sln[grep("2.NSFTV", sln$Level) ,][,3],
sln[grep("3.NSFTV", sln$Level) ,][,3]))
colnames(g.hat.y)=sub("1.", "", sln[grep("1.NSFTV", sln$Level) ,][,2])
Phi = stdtime(1:20, 2) %*% t(legendre(2, gengler = F))
ghat.t.y = t(apply(g.hat.y, 2, function (x) Phi %*% x))
colnames(ghat.t.y)=1:20
gBLUP.all=melt(ghat.t.y)
colnames(gBLUP.all)=c("NSFTV.ID", "DayOfImaging", "gBLUP")
}else{
sln=read.delim(Files[i], sep="", header=T)
g.hat.y=t(cbind(sln[grep("1.NSFTV", sln$Level) ,][,3],
sln[grep("2.NSFTV", sln$Level) ,][,3],
sln[grep("3.NSFTV", sln$Level) ,][,3]))
colnames(g.hat.y)=sub("1.", "", sln[grep("1.NSFTV", sln$Level) ,][,2])
Phi = stdtime(1:20, 2) %*% t(legendre(2, gengler = F))
ghat.t.y = t(apply(g.hat.y, 2, function (x) Phi %*% x))
colnames(ghat.t.y)=1:20
gBLUP=melt(ghat.t.y)
colnames(gBLUP)=c("NSFTV.ID", "DayOfImaging", "gBLUP")
if(i == 2 ){
final.blups=cbind(gBLUP.all, gBLUP[,3])
}else{
final.blups=cbind(final.blups, gBLUP[,3])
}
}
}
colnames(final.blups)[3:ncol(final.blups)]=sub(".sln", "", Files)
Cor.resTP.10=matrix(0, ncol=20, nrow=20)
final=read.csv("~/Desktop/ASREML_SA/RR_PSA.Cont/ScenarioD_CV/TP.10/final.CV_ScenD_10.csv")
setwd("~/Desktop/ASREML_SA/RR_PSA.Cont/ScenarioD_CV/TP.10/")
Files=c("PSA.sln", paste0("Y", 1:20, ".sln"))
for (i in 1:length(Files)){
if(Files[i] == "PSA.sln"){
#Requires the gBLUPs for PSA from the RR with ALL 20 timepoints
sln=read.delim(Files[i], sep="", header=T)
g.hat.y=t(cbind(sln[grep("1.NSFTV", sln$Level) ,][,3],
sln[grep("2.NSFTV", sln$Level) ,][,3],
sln[grep("3.NSFTV", sln$Level) ,][,3]))
colnames(g.hat.y)=sub("1.", "", sln[grep("1.NSFTV", sln$Level) ,][,2])
Phi = stdtime(1:20, 2) %*% t(legendre(2, gengler = F))
ghat.t.y = t(apply(g.hat.y, 2, function (x) Phi %*% x))
colnames(ghat.t.y)=1:20
gBLUP.all=melt(ghat.t.y)
colnames(gBLUP.all)=c("NSFTV.ID", "DayOfImaging", "gBLUP")
}else{
sln=read.delim(Files[i], sep="", header=T)
g.hat.y=t(cbind(sln[grep("1.NSFTV", sln$Level) ,][,3],
sln[grep("2.NSFTV", sln$Level) ,][,3],
sln[grep("3.NSFTV", sln$Level) ,][,3]))
colnames(g.hat.y)=sub("1.", "", sln[grep("1.NSFTV", sln$Level) ,][,2])
Phi = stdtime(1:20, 2) %*% t(legendre(2, gengler = F))
ghat.t.y = t(apply(g.hat.y, 2, function (x) Phi %*% x))
colnames(ghat.t.y)=1:20
gBLUP=melt(ghat.t.y)
colnames(gBLUP)=c("NSFTV.ID", "DayOfImaging", "gBLUP")
if(i == 2 ){
final.blups=cbind(gBLUP.all, gBLUP[,3])
}else{
final.blups=cbind(final.blups, gBLUP[,3])
}
}
}
colnames(final.blups)[3:ncol(final.blups)]=sub(".sln", "", Files)
Cor.resTP.10=matrix(0, ncol=20, nrow=20)
tmp=final[c("NSFTV.ID", colnames(final.blups)[j+2])]
colnames(tmp)[2]="Y"
tmp=ddply(tmp, .(NSFTV.ID), summarise, Cnt=sum(is.na(Y)))
summary(tmp)
for(j in 2:length(Files)){
tmp=final[c("NSFTV.ID", colnames(final.blups)[j+2])]
colnames(tmp)[2]="Y"
tmp=ddply(tmp, .(NSFTV.ID), summarise, Cnt=sum(is.na(Y)))
test.accTP.10=tmp[ tmp$Cnt == 60 ,]$NSFTV.ID
Cor.resTP.10[,j-1]=ldply(dlply(final.blups[final.blups$NSFTV.ID %in% test.accTP.10 ,][c(1,2,3,j+2)],
.(DayOfImaging), function(x) cor(x$PSA, x[,4], use="complete.obs") ) )[,2]
}
Cor.resTP.10.mean=apply(Cor.resTP.10, 1, mean)
Cor.resTP.10.sd=apply(Cor.resTP.10, 1, sd)
Cor.resTP.10.mean
Cor.resTP.7.mean
Cor.resTP.5.mean
final=read.csv("~/Desktop/ASREML_SA/RR_PSA.Cont/ScenarioD_CV/TP.15/final.CV_ScenD_15.csv")
setwd("~/Desktop/ASREML_SA/RR_PSA.Cont/ScenarioD_CV/TP.15/")
Files=c("PSA.sln", paste0("Y", 1:20, ".sln"))
for (i in 1:length(Files)){
if(Files[i] == "PSA.sln"){
#Requires the gBLUPs for PSA from the RR with ALL 20 timepoints
sln=read.delim(Files[i], sep="", header=T)
g.hat.y=t(cbind(sln[grep("1.NSFTV", sln$Level) ,][,3],
sln[grep("2.NSFTV", sln$Level) ,][,3],
sln[grep("3.NSFTV", sln$Level) ,][,3]))
colnames(g.hat.y)=sub("1.", "", sln[grep("1.NSFTV", sln$Level) ,][,2])
Phi = stdtime(1:20, 2) %*% t(legendre(2, gengler = F))
ghat.t.y = t(apply(g.hat.y, 2, function (x) Phi %*% x))
colnames(ghat.t.y)=1:20
gBLUP.all=melt(ghat.t.y)
colnames(gBLUP.all)=c("NSFTV.ID", "DayOfImaging", "gBLUP")
}else{
sln=read.delim(Files[i], sep="", header=T)
g.hat.y=t(cbind(sln[grep("1.NSFTV", sln$Level) ,][,3],
sln[grep("2.NSFTV", sln$Level) ,][,3],
sln[grep("3.NSFTV", sln$Level) ,][,3]))
colnames(g.hat.y)=sub("1.", "", sln[grep("1.NSFTV", sln$Level) ,][,2])
Phi = stdtime(1:20, 2) %*% t(legendre(2, gengler = F))
ghat.t.y = t(apply(g.hat.y, 2, function (x) Phi %*% x))
colnames(ghat.t.y)=1:20
gBLUP=melt(ghat.t.y)
colnames(gBLUP)=c("NSFTV.ID", "DayOfImaging", "gBLUP")
if(i == 2 ){
final.blups=cbind(gBLUP.all, gBLUP[,3])
}else{
final.blups=cbind(final.blups, gBLUP[,3])
}
}
}
colnames(final.blups)[3:ncol(final.blups)]=sub(".sln", "", Files)
Cor.resTP.15=matrix(0, ncol=20, nrow=20)
for(j in 2:length(Files)){
tmp=final[c("NSFTV.ID", colnames(final.blups)[j+2])]
colnames(tmp)[2]="Y"
tmp=ddply(tmp, .(NSFTV.ID), summarise, Cnt=sum(is.na(Y)))
test.accTP.15=tmp[ tmp$Cnt == 30 ,]$NSFTV.ID
Cor.resTP.15[,j-1]=ldply(dlply(final.blups[final.blups$NSFTV.ID %in% test.accTP.15 ,][c(1,2,3,j+2)],
.(DayOfImaging), function(x) cor(x$PSA, x[,4], use="complete.obs") ) )[,2]
}
summary(tmp)
Cor.resTP.15=matrix(0, ncol=20, nrow=20)
for(j in 2:length(Files)){
tmp=final[c("NSFTV.ID", colnames(final.blups)[j+2])]
colnames(tmp)[2]="Y"
tmp=ddply(tmp, .(NSFTV.ID), summarise, Cnt=sum(is.na(Y)))
test.accTP.15=tmp[ tmp$Cnt == 90 ,]$NSFTV.ID
Cor.resTP.15[,j-1]=ldply(dlply(final.blups[final.blups$NSFTV.ID %in% test.accTP.15 ,][c(1,2,3,j+2)],
.(DayOfImaging), function(x) cor(x$PSA, x[,4], use="complete.obs") ) )[,2]
}
Cor.resTP.15.mean=apply(Cor.resTP.15, 1, mean)
Cor.resTP.15.sd=apply(Cor.resTP.15, 1, sd)
final=read.csv("~/Desktop/ASREML_SA/RR_PSA.Cont/final_z.csv")
head(final)
final$Z=NULL
write.csv(final, "~/Desktop/Stat892/Phenotypes/Aus_PSA_Cont.csv", row.names = F)
final=read.csv("~/Desktop/Stat892/Phenotypes/Aus_PSA_Cont.csv")
#Get the mean PSA at each time point
ddPSA=ddply(final, .(DayOfImaging), summarise, Mean=mean(PSA/100000, na.rm=T), SD=sd(PSA/100000, na.rm=T))
knitr::opts_chunk$set(echo = TRUE)
final=read.csv("~/Desktop/Stat892/Phenotypes/Aus2014_PSA.csv")
final=read.csv("~/Desktop/Stat892/Phenotypes/Aus2014_PSA.csv")
head(final)
FAM=read.table("~/Desktop/Stat892/Genotypes/sativas413.fam")[1:2]
MAP=read.table("~/Desktop/Stat892/Genotypes/sativas413.map")
setwd("~/Desktop/Stat892/Genotypes/")
PED = read_ped("sativas413.ped")
m=PED$p
n=PED$n
PED=PED$x
##SNPs in PED are coded as 0, 1, 2, 3. 2 is missing data. 1 are heterozygous, 0 and 3 are homozygous for 1/1 and 2/2 for major allele and minor allele respectively
PED[PED == 2] <- NA
PED[PED==0]=0
PED[PED==1]=1
PED[PED==3]=2
W = t(matrix(PED, nrow=m, ncol=n, byrow = T))
colnames(W)=MAP$V2
rownames(W) <- FAM$V2
for (j in 1:ncol(W)) {
W[, j] = ifelse(is.na(W[, j]), mean(W[, j], na.rm = TRUE), W[, j])
}
W.orig=W
W=W.orig[row.names(W.orig) %in% final$NSFTV.ID ,]
freq = colMeans(W) / 2
maf = ifelse(freq > 0.5, 1-freq, freq)
maf.index = which(maf < 0.05)
length(maf.index)
W = W[, -maf.index]
####Estimate GRM using VanRaden's method
##NOTE that in the standalone of asreml the inverse of G is
##done after loading. So DO NOT take the inverse of G here!!!
Zsc = scale(x=W,center=T,scale=T)
G = tcrossprod(Zsc)/ncol(W)
G = G + diag(nrow(W))*0.001
G=G[match(unique(final$NSFTV.ID), row.names(G) ) ,]
G=G[, match(unique(final$NSFTV.ID), colnames(G) )]
##This chunk of code writes the GRM in a format that ASREML likes.
G.final <- as.data.frame(which(row(G)>=col(G),arr.ind=TRUE))
G.final$G <- G[lower.tri(G,diag=T)]
G.final <- G.final[,c(2,1,3)]
G.final <- G.final[order(G.final[,2],G.final[,1]),]
G.final <- G.final[,c(2,1,3)]
colnames(G.final)[1:2]=c("Row", "Column")
attr(G.final, "rowNames") = row.names(G)
write.table(G.final, "~/Desktop/Stat892/ASREML/G2.grm",col.names=F,row.names=F,quote=F,sep="\t")
WU=read.csv("~/Desktop/Stat892/Phenotypes/WUE.WU_cleaned.csv")
head(WU)
WU=WU[c("Exp", "NSFTV.ID", "Rep", "Water.Regime", "DayOfImaging", "WU")]
head(WU)
WU=WU[WU$Water.Regime %in% "Control" ,]
head(WU)
WU$Water.Regime=NULL
WU=WU[WU$DayOfImaging < 11 ,]
summary(WU)
final=final[final$DayOfImaging < 11 ,]
write.csv(WU, "~/Desktop/Stat892/Phenotypes/Aus2016_WU.csv", row.names = F)
write.csv(final, "~/Desktop/Stat892/Phenotypes/Aus2016_PSA.csv", row.names = F)
summary(final)
final=final[final$DayOfImaging > 0,]
final=final[final$Treatment %in% "Control" ,]
head(final)
summary(final)
write.csv(final, "~/Desktop/Stat892/Phenotypes/Aus2016_PSA.csv", row.names = F)
final=read.csv("~/Desktop/ASREML_SA/RR_PSA.Cont/final_z.csv")
summary(final)
final=final[final$DayOfImaging < 11 ,]
final$Water.Regime=NULL
final$Z=NULL
write.csv(final, "~/Desktop/Stat892/Phenotypes/Aus2016_PSA.csv", row.names = F)
length(unique(final$NSFTV.ID))
WU=read.csv("~/Desktop/Stat892/Phenotypes/Aus2016_WU.csv")
ddWU=ddply(final, .(DayOfImaging), summarise, Mean=mean(WU, na.rm=T), SD=sd(WU, na.rm=T))
par(mar=c(3,3,1,.2), mgp=c(1.8,0.5,0))
plot(ddWU$DayOfImaging, ddWU$Mean, pch=19, cex=0.3, ylab=expression(Water (grams^day)), xlab="Day of Imaging", col="black", ylim=c( 0, max(ddWU$Mean)*1.4) )
lines(ddWU$DayOfImaging, ddWU$Mean, col="black")
segments(ddWU$DayOfImaging, ddWU$Mean - ddWU$SD, 1:10, ddWU$Mean + ddWU$SD, lwd=1)
segments(1:10 - 0.1, ddWU$Mean - ddWU$SD, 1:10 + 0.1, ddWU$Mean - ddWU$SD, lwd=1)
segments(1:10 - 0.1, ddWU$Mean + ddWU$SD, 1:10 + 0.1, ddWU$Mean + ddWU$SD, lwd=1)
head(WU)
length(unique(WU$NSFTV.ID))
WU=read.csv("~/Desktop/Stat892/Phenotypes/Aus2016_WU.csv")
ddWU=ddply(WU, .(DayOfImaging), summarise, Mean=mean(WU, na.rm=T), SD=sd(WU, na.rm=T))
par(mar=c(3,3,1,.2), mgp=c(1.8,0.5,0))
plot(ddWU$DayOfImaging, ddWU$Mean, pch=19, cex=0.3, ylab=expression(Water (grams^day)), xlab="Day of Imaging", col="black", ylim=c( 0, max(ddWU$Mean)*1.4) )
lines(ddWU$DayOfImaging, ddWU$Mean, col="black")
segments(ddWU$DayOfImaging, ddWU$Mean - ddWU$SD, 1:10, ddWU$Mean + ddWU$SD, lwd=1)
segments(1:10 - 0.1, ddWU$Mean - ddWU$SD, 1:10 + 0.1, ddWU$Mean - ddWU$SD, lwd=1)
segments(1:10 - 0.1, ddWU$Mean + ddWU$SD, 1:10 + 0.1, ddWU$Mean + ddWU$SD, lwd=1)
par(mar=c(3,3,1,.2), mgp=c(1.8,0.5,0))
plot(ddWU$DayOfImaging, ddWU$Mean, pch=19, cex=0.3, ylab=expression(Water (grams %.% day^-1)), xlab="Day of Imaging", col="black", ylim=c( 0, max(ddWU$Mean)*1.4) )
lines(ddWU$DayOfImaging, ddWU$Mean, col="black")
segments(ddWU$DayOfImaging, ddWU$Mean - ddWU$SD, 1:10, ddWU$Mean + ddWU$SD, lwd=1)
segments(1:10 - 0.1, ddWU$Mean - ddWU$SD, 1:10 + 0.1, ddWU$Mean - ddWU$SD, lwd=1)
segments(1:10 - 0.1, ddWU$Mean + ddWU$SD, 1:10 + 0.1, ddWU$Mean + ddWU$SD, lwd=1)
